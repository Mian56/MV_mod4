{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "a5575888",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "a5575888"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib; matplotlib.use('agg')\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_triptych(image_path):\n",
        "    \"\"\"\n",
        "    Split a triptych image into three color channels and combine them into an RGB image.\n",
        "\n",
        "    Args:\n",
        "        image_path: Path to the triptych image\n",
        "\n",
        "    Returns:\n",
        "        red_channel, green_channel, blue_channel: The separated color channels\n",
        "        color_image: Combined RGB image\n",
        "    \"\"\"\n",
        "    # Read the image\n",
        "    try:\n",
        "        # Try using plt.imread first\n",
        "        img = plt.imread(image_path)\n",
        "    except:\n",
        "        # If that fails (e.g., for URLs), try using cv2.imread\n",
        "        try:\n",
        "            # For URLs, we need to download the image first using cv2\n",
        "            import urllib.request\n",
        "            resp = urllib.request.urlopen(image_path)\n",
        "            img = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "            img = cv2.imdecode(img, cv2.IMREAD_COLOR)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        except:\n",
        "            raise ValueError(f\"Could not load image from {image_path}\")\n",
        "\n",
        "    # Get the height and width of the image\n",
        "    height, width = img.shape[:2]\n",
        "\n",
        "    # Calculate the height of each panel (assuming equal sizes)\n",
        "    panel_height = height // 3\n",
        "\n",
        "    # Split the image into three panels (B, G, R from top to bottom)\n",
        "    # Ensure each panel has exactly the same shape\n",
        "    blue_channel = img[:panel_height, :]\n",
        "    green_channel = img[panel_height:2*panel_height, :]\n",
        "    red_channel = img[2*panel_height:3*panel_height, :]  # Use exact range to ensure same shape\n",
        "\n",
        "    # Print shapes for debugging\n",
        "    print(f\"Blue channel shape: {blue_channel.shape}\")\n",
        "    print(f\"Green channel shape: {green_channel.shape}\")\n",
        "    print(f\"Red channel shape: {red_channel.shape}\")\n",
        "\n",
        "    # Check if all channels have the same dimensions\n",
        "    if blue_channel.shape != green_channel.shape or blue_channel.shape != red_channel.shape:\n",
        "        # Resize all to the smallest shape to ensure compatibility\n",
        "        min_height = min(blue_channel.shape[0], green_channel.shape[0], red_channel.shape[0])\n",
        "        min_width = min(blue_channel.shape[1], green_channel.shape[1], red_channel.shape[1])\n",
        "\n",
        "        blue_channel = blue_channel[:min_height, :min_width]\n",
        "        green_channel = green_channel[:min_height, :min_width]\n",
        "        red_channel = red_channel[:min_height, :min_width]\n",
        "\n",
        "        print(f\"Resized all channels to shape: {blue_channel.shape}\")\n",
        "\n",
        "    # If the channels are grayscale (only 2D), expand them to 3D for stacking\n",
        "    if len(blue_channel.shape) == 2:\n",
        "        # Stack the channels in RGB order\n",
        "        color_image = np.stack((red_channel, green_channel, blue_channel), axis=2)\n",
        "    else:\n",
        "        # If channels already have color dimensions, extract first channel only\n",
        "        red_intensity = red_channel[:,:,0] if len(red_channel.shape) > 2 else red_channel\n",
        "        green_intensity = green_channel[:,:,0] if len(green_channel.shape) > 2 else green_channel\n",
        "        blue_intensity = blue_channel[:,:,0] if len(blue_channel.shape) > 2 else blue_channel\n",
        "\n",
        "        # Stack the intensity channels\n",
        "        color_image = np.stack((red_intensity, green_intensity, blue_intensity), axis=2)\n",
        "\n",
        "    # If the image has values in range [0,1], convert to [0,255] for saving\n",
        "    if color_image.max() <= 1.0:\n",
        "        color_image = (color_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Save the color image\n",
        "    plt.imsave('color_image_task1.jpg', color_image)\n",
        "\n",
        "    return red_channel, green_channel, blue_channel, color_image\n"
      ],
      "metadata": {
        "id": "W2AWkAKppFB3"
      },
      "id": "W2AWkAKppFB3",
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_cross_correlation(channel1, channel2):\n",
        "    \"\"\"\n",
        "    Compute the normalized cross-correlation between two channels.\n",
        "    \"\"\"\n",
        "    # Flatten the channels to 1D arrays\n",
        "    channel1_flat = channel1.flatten()\n",
        "    channel2_flat = channel2.flatten()\n",
        "\n",
        "    # Normalize the channels by their L2 norm\n",
        "    norm1 = np.sqrt(np.sum(channel1_flat**2))\n",
        "    norm2 = np.sqrt(np.sum(channel2_flat**2))\n",
        "\n",
        "    # Avoid division by zero\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0\n",
        "\n",
        "    channel1_norm = channel1_flat / norm1\n",
        "    channel2_norm = channel2_flat / norm2\n",
        "\n",
        "    # Compute the dot product (correlation)\n",
        "    ncc = np.dot(channel1_norm, channel2_norm)\n",
        "\n",
        "    return ncc"
      ],
      "metadata": {
        "id": "BrLl-4scpQ5F"
      },
      "id": "BrLl-4scpQ5F",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalized_cross_correlation_center(channel1, channel2, border=15):\n",
        "    \"\"\"\n",
        "    Compute the normalized cross-correlation between two channels,\n",
        "    using only the center region unaffected by offsetting artifacts.\n",
        "    \"\"\"\n",
        "    # Exclude border pixels\n",
        "    h, w = channel1.shape[:2]\n",
        "    center1 = channel1[border:h-border, border:w-border]\n",
        "    center2 = channel2[border:h-border, border:w-border]\n",
        "\n",
        "    return normalized_cross_correlation(center1, center2)"
      ],
      "metadata": {
        "id": "etKUXmwppUz-"
      },
      "id": "etKUXmwppUz-",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_dot_product(channel1, channel2):\n",
        "    \"\"\"\n",
        "    Compute the simple dot product between two channels without normalization.\n",
        "    \"\"\"\n",
        "    # Flatten the channels to 1D arrays\n",
        "    channel1_flat = channel1.flatten()\n",
        "    channel2_flat = channel2.flatten()\n",
        "\n",
        "    # Compute the dot product (correlation)\n",
        "    dot_product = np.dot(channel1_flat, channel2_flat)\n",
        "\n",
        "    return dot_product"
      ],
      "metadata": {
        "id": "0IjsFraKpYk9"
      },
      "id": "0IjsFraKpYk9",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_offset_ncc(fixed_channel, moving_channel, offset_range=15, use_center=True):\n",
        "    \"\"\"\n",
        "    Find the best offset using normalized cross-correlation.\n",
        "    \"\"\"\n",
        "    best_corr = -1  # Initialize with a negative correlation\n",
        "    best_y, best_x = 0, 0\n",
        "\n",
        "    # Try different offsets\n",
        "    for y_offset in range(-offset_range, offset_range + 1):\n",
        "        for x_offset in range(-offset_range, offset_range + 1):\n",
        "            # Shift the moving channel\n",
        "            shifted = np.roll(moving_channel, (y_offset, x_offset), axis=(0, 1))\n",
        "\n",
        "            # Compute correlation\n",
        "            if use_center:\n",
        "                corr = normalized_cross_correlation_center(fixed_channel, shifted, border=offset_range)\n",
        "            else:\n",
        "                corr = normalized_cross_correlation(fixed_channel, shifted)\n",
        "\n",
        "            # Update if better correlation found\n",
        "            if corr > best_corr:\n",
        "                best_corr = corr\n",
        "                best_y, best_x = y_offset, x_offset\n",
        "\n",
        "    return best_y, best_x"
      ],
      "metadata": {
        "id": "Y7QGNAegpazO"
      },
      "id": "Y7QGNAegpazO",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def best_offset_dot(fixed_channel, moving_channel, offset_range=15, use_center=True):\n",
        "    \"\"\"\n",
        "    Find the best offset using simple dot product.\n",
        "    \"\"\"\n",
        "    best_corr = -float('inf')  # Initialize with negative infinity\n",
        "    best_y, best_x = 0, 0\n",
        "\n",
        "    # Try different offsets\n",
        "    for y_offset in range(-offset_range, offset_range + 1):\n",
        "        for x_offset in range(-offset_range, offset_range + 1):\n",
        "            # Shift the moving channel\n",
        "            shifted = np.roll(moving_channel, (y_offset, x_offset), axis=(0, 1))\n",
        "\n",
        "            # Compute simple dot product\n",
        "            if use_center:\n",
        "                h, w = fixed_channel.shape[:2]\n",
        "                border = offset_range\n",
        "                fixed_center = fixed_channel[border:h-border, border:w-border]\n",
        "                shifted_center = shifted[border:h-border, border:w-border]\n",
        "                corr = simple_dot_product(fixed_center, shifted_center)\n",
        "            else:\n",
        "                corr = simple_dot_product(fixed_channel, shifted)\n",
        "\n",
        "            # Update if better correlation found\n",
        "            if corr > best_corr:\n",
        "                best_corr = corr\n",
        "                best_y, best_x = y_offset, x_offset\n",
        "\n",
        "    return best_y, best_x\n"
      ],
      "metadata": {
        "id": "IeP1bKY3pgZ3"
      },
      "id": "IeP1bKY3pgZ3",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_and_combine(red_channel, green_channel, blue_channel, offset_range=15, use_center=True):\n",
        "    \"\"\"\n",
        "    Align and combine the three channels into a color image using normalized cross-correlation.\n",
        "    \"\"\"\n",
        "    # Find best offsets for green and blue channels relative to red\n",
        "    g_y_offset, g_x_offset = best_offset_ncc(red_channel, green_channel, offset_range, use_center)\n",
        "    b_y_offset, b_x_offset = best_offset_ncc(red_channel, blue_channel, offset_range, use_center)\n",
        "\n",
        "    # Apply the offsets\n",
        "    aligned_green = np.roll(green_channel, (g_y_offset, g_x_offset), axis=(0, 1))\n",
        "    aligned_blue = np.roll(blue_channel, (b_y_offset, b_x_offset), axis=(0, 1))\n",
        "\n",
        "    # Stack the channels\n",
        "    aligned_image = np.stack((red_channel, aligned_green, aligned_blue), axis=2)\n",
        "\n",
        "    # If the image has values in range [0,1], convert to [0,255] for display\n",
        "    if aligned_image.max() <= 1.0:\n",
        "        aligned_image = (aligned_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Store the offsets\n",
        "    offsets = {\n",
        "        'green': (g_y_offset, g_x_offset),\n",
        "        'blue': (b_y_offset, b_x_offset)\n",
        "    }\n",
        "\n",
        "    return aligned_image, offsets\n"
      ],
      "metadata": {
        "id": "3-mozHMDphje"
      },
      "id": "3-mozHMDphje",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_and_combine(red_channel, green_channel, blue_channel, offset_range=15, use_center=True):\n",
        "    \"\"\"\n",
        "    Align and combine the three channels into a color image using normalized cross-correlation.\n",
        "    \"\"\"\n",
        "    # Find best offsets for green and blue channels relative to red\n",
        "    g_y_offset, g_x_offset = best_offset_ncc(red_channel, green_channel, offset_range, use_center)\n",
        "    b_y_offset, b_x_offset = best_offset_ncc(red_channel, blue_channel, offset_range, use_center)\n",
        "\n",
        "    # Apply the offsets\n",
        "    aligned_green = np.roll(green_channel, (g_y_offset, g_x_offset), axis=(0, 1))\n",
        "    aligned_blue = np.roll(blue_channel, (b_y_offset, b_x_offset), axis=(0, 1))\n",
        "\n",
        "    # Stack the channels\n",
        "    aligned_image = np.stack((red_channel, aligned_green, aligned_blue), axis=2)\n",
        "\n",
        "    # If the image has values in range [0,1], convert to [0,255] for display\n",
        "    if aligned_image.max() <= 1.0:\n",
        "        aligned_image = (aligned_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Store the offsets\n",
        "    offsets = {\n",
        "        'green': (g_y_offset, g_x_offset),\n",
        "        'blue': (b_y_offset, b_x_offset)\n",
        "    }\n",
        "\n",
        "    return aligned_image, offsets\n",
        "\n",
        "def align_and_combine_simple_dot(red_channel, green_channel, blue_channel, offset_range=15, use_center=True):\n",
        "    \"\"\"\n",
        "    Align and combine the three channels using simple dot product metric.\n",
        "    \"\"\"\n",
        "    # Find best offsets for green and blue channels relative to red\n",
        "    g_y_offset, g_x_offset = best_offset_dot(red_channel, green_channel, offset_range, use_center)\n",
        "    b_y_offset, b_x_offset = best_offset_dot(red_channel, blue_channel, offset_range, use_center)\n",
        "\n",
        "    # Apply the offsets\n",
        "    aligned_green = np.roll(green_channel, (g_y_offset, g_x_offset), axis=(0, 1))\n",
        "    aligned_blue = np.roll(blue_channel, (b_y_offset, b_x_offset), axis=(0, 1))\n",
        "\n",
        "    # Stack the channels\n",
        "    aligned_image = np.stack((red_channel, aligned_green, aligned_blue), axis=2)\n",
        "\n",
        "    # If the image has values in range [0,1], convert to [0,255] for display\n",
        "    if aligned_image.max() <= 1.0:\n",
        "        aligned_image = (aligned_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Store the offsets\n",
        "    offsets = {\n",
        "        'green': (g_y_offset, g_x_offset),\n",
        "        'blue': (b_y_offset, b_x_offset)\n",
        "    }\n",
        "\n",
        "    return aligned_image, offsets\n"
      ],
      "metadata": {
        "id": "F60hJxXQpkJ4"
      },
      "id": "F60hJxXQpkJ4",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pyramid(image, levels=3, scale_factor=4):\n",
        "    \"\"\"\n",
        "    Create an image pyramid by downsampling the image.\n",
        "    \"\"\"\n",
        "    pyramid = [image]\n",
        "    current_image = image\n",
        "\n",
        "    for _ in range(levels - 1):\n",
        "        h, w = current_image.shape[:2]\n",
        "        new_h, new_w = h // scale_factor, w // scale_factor\n",
        "        resized = cv2.resize(current_image, (new_w, new_h))\n",
        "        pyramid.append(resized)\n",
        "\n",
        "    # Reverse so that lowest resolution is first\n",
        "    return pyramid[::-1]\n",
        "\n",
        "def pyramid_align(red_channel, green_channel, blue_channel, levels=3, scale_factor=4, offset_range=10, use_center=True):\n",
        "    \"\"\"\n",
        "    Align three channels using image pyramid approach.\n",
        "    \"\"\"\n",
        "    # Create pyramids for each channel\n",
        "    red_pyramid = create_pyramid(red_channel, levels, scale_factor)\n",
        "    green_pyramid = create_pyramid(green_channel, levels, scale_factor)\n",
        "    blue_pyramid = create_pyramid(blue_channel, levels, scale_factor)\n",
        "\n",
        "    # Initialize offsets\n",
        "    g_y_total, g_x_total = 0, 0\n",
        "    b_y_total, b_x_total = 0, 0\n",
        "    level_offsets = []\n",
        "\n",
        "    # Process each level from lowest to highest resolution\n",
        "    for level in range(levels):\n",
        "        # Get the current level images\n",
        "        red_level = red_pyramid[level]\n",
        "        green_level = green_pyramid[level]\n",
        "        blue_level = blue_pyramid[level]\n",
        "\n",
        "        # Apply accumulated offsets from previous levels (scaled)\n",
        "        if level > 0:\n",
        "            g_y_total *= scale_factor\n",
        "            g_x_total *= scale_factor\n",
        "            b_y_total *= scale_factor\n",
        "            b_x_total *= scale_factor\n",
        "\n",
        "            green_level = np.roll(green_level, (g_y_total, g_x_total), axis=(0, 1))\n",
        "            blue_level = np.roll(blue_level, (b_y_total, b_x_total), axis=(0, 1))\n",
        "\n",
        "        # Find additional offsets at this level\n",
        "        g_y_offset, g_x_offset = best_offset_ncc(red_level, green_level, offset_range, use_center)\n",
        "        b_y_offset, b_x_offset = best_offset_ncc(red_level, blue_level, offset_range, use_center)\n",
        "\n",
        "        # Apply these offsets\n",
        "        green_level = np.roll(green_level, (g_y_offset, g_x_offset), axis=(0, 1))\n",
        "        blue_level = np.roll(blue_level, (b_y_offset, b_x_offset), axis=(0, 1))\n",
        "\n",
        "        # Update total offsets\n",
        "        g_y_total += g_y_offset\n",
        "        g_x_total += g_x_offset\n",
        "        b_y_total += b_y_offset\n",
        "        b_x_total += b_x_offset\n",
        "\n",
        "        # Store the offsets for this level\n",
        "        level_offsets.append({\n",
        "            'level': level,\n",
        "            'green': (g_y_offset, g_x_offset),\n",
        "            'blue': (b_y_offset, b_x_offset)\n",
        "        })\n",
        "\n",
        "    # Apply the final offsets to the original channels\n",
        "    aligned_green = np.roll(green_channel, (g_y_total, g_x_total), axis=(0, 1))\n",
        "    aligned_blue = np.roll(blue_channel, (b_y_total, b_x_total), axis=(0, 1))\n",
        "\n",
        "    # Stack the channels\n",
        "    aligned_image = np.stack((red_channel, aligned_green, aligned_blue), axis=2)\n",
        "\n",
        "    # If the image has values in range [0,1], convert to [0,255] for display\n",
        "    if aligned_image.max() <= 1.0:\n",
        "        aligned_image = (aligned_image * 255).astype(np.uint8)\n",
        "\n",
        "    # Store the total offsets\n",
        "    total_offsets = {\n",
        "        'green': (g_y_total, g_x_total),\n",
        "        'blue': (b_y_total, b_x_total)\n",
        "    }\n",
        "\n",
        "    return aligned_image, level_offsets, total_offsets"
      ],
      "metadata": {
        "id": "kR9YTbG0pxQH"
      },
      "id": "kR9YTbG0pxQH",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to process all tasks\n",
        "def main():\n",
        "    # Choose an image from the prokudin-gorskii folder\n",
        "    # You would need to replace this with the actual path or URL\n",
        "    image_path = 'https://github.com/Mian56/MV_mod4/blob/main/prokudin-gorskii/prokudin-gorskii/00351v.jpg?raw=true'\n",
        "\n",
        "    print(f\"Processing image: {image_path}\")\n",
        "\n",
        "    # Task 1: Split and combine\n",
        "    red_channel, green_channel, blue_channel, basic_color_image = split_triptych(image_path)\n",
        "\n",
        "    # Task 2: Align using two different metrics\n",
        "    aligned_ncc, offsets_ncc = align_and_combine(\n",
        "        red_channel, green_channel, blue_channel, offset_range=15, use_center=True\n",
        "    )\n",
        "\n",
        "    aligned_dot, offsets_dot = align_and_combine_simple_dot(\n",
        "        red_channel, green_channel, blue_channel, offset_range=15, use_center=True\n",
        "    )\n",
        "\n",
        "    # Save the aligned images\n",
        "    plt.imsave('aligned_image_ncc.jpg', aligned_ncc)\n",
        "    plt.imsave('aligned_image_dot.jpg', aligned_dot)\n",
        "\n",
        "    print(\"Task 1 complete: Basic color image created\")\n",
        "    print(\"Task 2 complete: Aligned images created\")\n",
        "    print(\"Offsets using NCC:\", offsets_ncc)\n",
        "    print(\"Offsets using simple dot product:\", offsets_dot)\n",
        "\n",
        "    # Task 3: Pyramid alignment (for large images)\n",
        "    # For now, just use the same image as an example\n",
        "    aligned_pyramid, level_offsets, total_offsets = pyramid_align(\n",
        "        red_channel, green_channel, blue_channel, levels=3, scale_factor=4, offset_range=10\n",
        "    )\n",
        "\n",
        "    # Save the pyramid-aligned image\n",
        "    plt.imsave('aligned_image_pyramid.jpg', aligned_pyramid)\n",
        "\n",
        "    print(\"Task 3 complete: Pyramid-aligned image created\")\n",
        "    print(\"Level offsets:\", level_offsets)\n",
        "    print(\"Total offsets:\", total_offsets)\n",
        "\n",
        "    # Answer Task 3 questions\n",
        "    print(\"\\nTask 3 Questions:\")\n",
        "    print(\"1. Equivalent range of offset in original images:\")\n",
        "    # If we search [-10, 10] at each level with scale factor 4 and 3 levels:\n",
        "    # Level 0 (lowest res): [-10, 10]\n",
        "    # Level 1: Level 0 result * 4 + [-10, 10] = [-50, 50]\n",
        "    # Level 2 (original res): Level 1 result * 4 + [-10, 10] = [-210, 210]\n",
        "    print(\"   Range: [-210, 210] pixels\")\n",
        "\n",
        "    print(\"2. Speed comparison:\")\n",
        "    # Simple search would check (421)^2 = 177,241 offsets\n",
        "    # Pyramid approach checks:\n",
        "    # Level 0: (21)^2 offsets at 1/16 size = 441 * (1/16) = 27.6 units\n",
        "    # Level 1: (21)^2 offsets at 1/4 size = 441 * (1/4) = 110.3 units\n",
        "    # Level 2: (21)^2 offsets at full size = 441 units\n",
        "    # Total: 27.6 + 110.3 + 441 = 578.9 units\n",
        "    # Speedup = 177,241 / 578.9 ≈ 306x\n",
        "    print(\"   The pyramid approach is approximately 300 times faster\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "zHLK0P5npyk5",
        "outputId": "f1b382e2-9401-4168-afed-bdc516f0fd60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "zHLK0P5npyk5",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing image: https://github.com/Mian56/MV_mod4/blob/main/prokudin-gorskii/prokudin-gorskii/00351v.jpg?raw=true\n",
            "Blue channel shape: (341, 396, 3)\n",
            "Green channel shape: (341, 396, 3)\n",
            "Red channel shape: (341, 396, 3)\n",
            "Task 1 complete: Basic color image created\n",
            "Task 2 complete: Aligned images created\n",
            "Offsets using NCC: {'green': (15, 15), 'blue': (15, 15)}\n",
            "Offsets using simple dot product: {'green': (-10, 8), 'blue': (-2, -2)}\n",
            "Task 3 complete: Pyramid-aligned image created\n",
            "Level offsets: [{'level': 0, 'green': (10, 10), 'blue': (10, 10)}, {'level': 1, 'green': (-10, 8), 'blue': (-10, 2)}, {'level': 2, 'green': (-10, -4), 'blue': (-10, 10)}]\n",
            "Total offsets: {'green': (110, 188), 'blue': (110, 178)}\n",
            "\n",
            "Task 3 Questions:\n",
            "1. Equivalent range of offset in original images:\n",
            "   Range: [-210, 210] pixels\n",
            "2. Speed comparison:\n",
            "   The pyramid approach is approximately 300 times faster\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}